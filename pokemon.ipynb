{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary libraries\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to cuda if available\n",
    "def_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Clear the cache and empty the GPU memory if cuda is available\n",
    "if def_device == 'cuda':\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load tensors into GPU\n",
    "# Very useful when we have to load a batch of tensors into GPU and makes life easier\n",
    "\n",
    "def to_device(x,device = def_device):\n",
    "  if isinstance(x, torch.Tensor): return x.to(device) # if x is a tensor, move it to the device\n",
    "  return type(x)(to_device(o, device) for o in x) # if x is a list or tuple, recursively move all the elements to the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data directory\n",
    "\n",
    "data_dir = \"archive/PokemonData\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all the pokemon names\n",
    "\n",
    "pokemon_names = os.listdir(data_dir)\n",
    "len(pokemon_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of all the image paths and their corresponding classes\n",
    "# Create a dictionary of pokemon names and their corresponding index for easy lookup\n",
    "\n",
    "image_paths = []\n",
    "image_classes = []\n",
    "int_to_class = {}\n",
    "class_to_int = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the directory and get the image paths and classes\n",
    "\n",
    "for i in range(len(pokemon_names)):\n",
    "    image_names = os.listdir(data_dir+'/' + pokemon_names[i])\n",
    "    int_to_class[i] = pokemon_names[i]\n",
    "    class_to_int[pokemon_names[i]] = i\n",
    "    for j in range(len(image_names)):\n",
    "        if image_names[j][-3:] == 'jpg':\n",
    "            image_paths.append(data_dir +'/'+ pokemon_names[i] + \"/\" + image_names[j])\n",
    "            image_classes.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the image paths and classes\n",
    "# This is done so that we can split the dataset into train and validation sets and also to make sure that the model doesn't overfit on a particular class\n",
    "# There are probably better ways to do this but this is one way that does the job\n",
    "\n",
    "rng_state = np.random.get_state()\n",
    "np.random.shuffle(image_paths)\n",
    "np.random.set_state(rng_state)\n",
    "np.random.shuffle(image_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the split ratio for train and validation sets\n",
    "\n",
    "train_spilt = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and validation sets\n",
    "\n",
    "train_paths = image_paths[:int(len(image_paths)*train_spilt)]\n",
    "train_classes = image_classes[:int(len(image_paths)*train_spilt)]\n",
    "\n",
    "test_paths = image_paths[int(len(image_paths)*train_spilt):]\n",
    "test_classes = image_classes[int(len(image_paths)*train_spilt):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transforms for train and validation sets\n",
    "# The transforms are defined in such a way that the model can learn the features of the pokemon and not the background\n",
    "# The training set has random transformations applied to it so that the model can learn the features of the pokemon from different angles and positions\n",
    "# Also data augmentation is done to increase the size of the dataset and to make the model more robust and to prevent overfitting\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "])  \n",
    "\n",
    "# The validation set has no random transformations applied to it \n",
    "# We resize the image to 224x224 and convert it to a tensor which is the input format for the resnet50 model\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])  \n",
    "\n",
    "# This is a normalization transform that is applied to the input images\n",
    "# The values are taken from the resnet50 model documentation\n",
    "# It helps the model to learn faster\n",
    "normalization_transform = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our own dataset class\n",
    "# This is done so that we can load the images in batches and apply the transforms to them\n",
    "# Inherit the torch.utils.data.Dataset class and override the __len__ and __getitem__ methods\n",
    "# __len__ method returns the length of the dataset\n",
    "# __getitem__ method returns the image and its corresponding class\n",
    "\n",
    "\n",
    "class PokemonDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_paths, image_classes, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.image_classes = image_classes\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        while True:\n",
    "          # Try except block is used because some of the images in the dataset are corrupted and cannot be opened\n",
    "          # So we try to open the image and if it fails we randomly select another image\n",
    "          try:                         \n",
    "            image = Image.open(self.image_paths[idx])\n",
    "            break\n",
    "          except:\n",
    "            idx = random.randint(0,len(self.image_paths)-1)\n",
    "        # Apply the transforms to the image\n",
    "        image = self.transform(image)\n",
    "\n",
    "        # Some of the images in the dataset have 1 and 4 channels instead of 3\n",
    "        # So we repeat the channels if the image has 1 channel and remove the alpha channel if the image has 4 channels\n",
    "        if image.shape[0] == 1:\n",
    "            image = image.repeat(3,1,1)\n",
    "        elif image.shape[0] == 4:\n",
    "            image = image[:3,:,:]\n",
    "\n",
    "        # Apply the normalization transform to the image and return the image and its corresponding class\n",
    "        image = normalization_transform(image)\n",
    "        return image, self.image_classes[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train and validation datasets using the PokemonDataset class and the transforms defined above\n",
    "\n",
    "train_dataset = PokemonDataset(train_paths, train_classes, transform=train_transform)\n",
    "test_dataset = PokemonDataset(test_paths, test_classes, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train and validation dataloaders \n",
    "# Set the batch size and shuffle the train dataloader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize an image from the train dataloader\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "img,label = batch\n",
    "img = img[0]\n",
    "img = img.permute(1,2,0)\n",
    "plt.imshow(img)\n",
    "plt.title(int_to_class[int(label[0])])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize an image from the validation dataloader\n",
    "\n",
    "batch = next(iter(test_loader))\n",
    "img,label = batch\n",
    "img = img[0]\n",
    "img = img.permute(1,2,0)\n",
    "plt.imshow(img)\n",
    "plt.title(int_to_class[int(label[0])])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ResBlock class\n",
    "# This is used to create the resnet50 model\n",
    "# This the basic building block of the resnet50 model which is repeated multiple times to create the model\n",
    "# The code for this class is taken from the pytorch documentation\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1,\n",
    "                     padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a layer of the resnet50 model\n",
    "# A layer consists of multiple ResBlocks with same number of input and output channels\n",
    "# The code for this function is taken from the pytorch documentation\n",
    "\n",
    "def _make_layer(block,inplanes,planes, blocks, stride=1):\n",
    "    downsample = None\n",
    "    if stride != 1 or inplanes != planes:\n",
    "        downsample = nn.Sequential(\n",
    "            nn.Conv2d(inplanes, planes, 1, stride, bias=False),\n",
    "            nn.BatchNorm2d(planes),\n",
    "        )\n",
    "    layers = []\n",
    "    layers.append(block(inplanes, planes, stride, downsample))\n",
    "    inplanes = planes\n",
    "    for _ in range(1, blocks):\n",
    "        layers.append(block(inplanes, planes))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ResNet class\n",
    "# Put together all the layers to create the resnet50 model\n",
    "# Define the forward method which is used to pass the input through the model\n",
    "# The code for this class is taken from the pytorch documentation\n",
    "# Set the number of classes to 150 since we have 150 pokemon classes\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=150):\n",
    "        super().__init__()\n",
    "\n",
    "        self.inplanes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = _make_layer(block,self.inplanes, 64, layers[0])\n",
    "        self.layer2 = _make_layer(block,64, 128, layers[1], stride=2)\n",
    "        self.layer3 = _make_layer(block,128, 256, layers[2], stride=2)\n",
    "        self.layer4 = _make_layer(block,256, 512, layers[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 , num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)           # 224x224\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)         # 112x112\n",
    "\n",
    "        x = self.layer1(x)          # 56x56\n",
    "        x = self.layer2(x)          # 28x28\n",
    "        x = self.layer3(x)          # 14x14\n",
    "        x = self.layer4(x)          # 7x7\n",
    "\n",
    "        x = self.avgpool(x)         # 1x1\n",
    "        x = torch.flatten(x, 1)     # convert 1 X 1 to vector\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ResNet(ResBlock, [3, 4, 6, 3])  # ResNet50 model. The values 3,4,6,3 are taken from the paper\n",
    "\n",
    "# Load the resnet50 model if it is already trained\n",
    "model = torch.load('pokemon_classifier.pth')\n",
    "\n",
    "# Send the model to the device (GPU or CPU)\n",
    "model = model.to(def_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evalute the model on the test dataset\n",
    "\n",
    "def evaluate(model, test_dl, crit):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    tot_loss = 0\n",
    "    model.eval() # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # No need to calculate gradients when evaluating the model\n",
    "        for x, y in test_dl:\n",
    "            x = to_device(x)\n",
    "            y = to_device(y)\n",
    "            o = model(x)\n",
    "            l = crit(o,y)\n",
    "            tot_loss += l.item()\n",
    "            correct += torch.sum(torch.argmax(o,axis=1) == y).item()\n",
    "            total += len(y)\n",
    "        test_loss = tot_loss / len(test_dl)\n",
    "        test_acc = 100 * correct / total\n",
    "        return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model for one epoch on the train datset\n",
    "\n",
    "def train_one_epoch(model, train_dl, crit, optim):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    tot_loss = 0\n",
    "    model.train() # Set the model to training mode\n",
    "    for x, y in tqdm(train_dl,total=len(train_dl)):\n",
    "        optim.zero_grad()\n",
    "        x = to_device(x)\n",
    "        y = to_device(y)\n",
    "        o = model(x)\n",
    "        l = crit(o,y)\n",
    "        l.backward()\n",
    "        optim.step()\n",
    "        tot_loss += l.item()\n",
    "        correct += torch.sum(torch.argmax(o,axis=1) == y).item()\n",
    "        total += len(y)\n",
    "    train_loss = tot_loss / len(train_dl)\n",
    "    train_acc = 100 * correct / total\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for the specified number of epochs\n",
    "\n",
    "def train(model, train_dl, test_dl, crit, optim, lr_sched=None, epochs=10):\n",
    "    for epoch in tqdm(range(epochs),total=epochs):\n",
    "        train_loss, train_acc = train_one_epoch(model, train_dl, crit, optim)\n",
    "        test_loss, test_acc = evaluate(model, test_dl, crit)\n",
    "        if lr_sched is not None:\n",
    "            lr_sched.step() # Update the learning rate if a scheduler is passed\n",
    "        print(f\"epoch: {epoch}, train loss: {train_loss}, train accuracy: {train_acc:.2f}%, test loss: {test_loss}, test accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer, learning rate scheduler and the loss function\n",
    "# I have used the SGD optimizer with momentum and the CosineAnnealingLR learning rate scheduler\n",
    "# The loss function is the cross entropy loss function\n",
    "# You can also use Adam with any learning rate scheduler of your choice\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "lr_sched = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model for 15 epochs\n",
    "# Also I tried to use tqdm for the progress bar but it didn't work as expected so \n",
    "# progress bars might be little buggy\n",
    "\n",
    "train(model, train_loader, test_loader, criterion, optimizer, epochs=15, lr_sched=lr_sched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "\n",
    "torch.save(model, 'pokemon_classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model into CPU before inference\n",
    "\n",
    "model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the class of an image given its path and true class\n",
    "\n",
    "def predict(image_path, label):\n",
    "    img = Image.open(image_path)\n",
    "    plt.imshow(img)\n",
    "\n",
    "    # Apply the transforms to the image and convert it to a tensor (Necessary for the model as it was trained using such a transformation)\n",
    "    img = test_transform(img) \n",
    "    img = normalization_transform(img) \n",
    "    img = img.unsqueeze(0) # Add a batch dimension to the image \n",
    "\n",
    "    # Pass the image through the model and get the prediction and the corresponding class\n",
    "    # Plot the image and the predicted class along with the true class\n",
    "\n",
    "    model.eval() # Set the model to evaluation mode\n",
    "    pred = model(img)\n",
    "    predicted_class = np.argmax(pred.detach().numpy())\n",
    "    class_ = int_to_class[int(predicted_class)]\n",
    "    plt.title(f\"True: {int_to_class[int(label)]}    Predicted: {class_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the predictions of the model on the dataset\n",
    "# Select a random image from the dataset\n",
    "\n",
    "num = random.randint(0,len(image_paths)-1) \n",
    "img = image_paths[num]\n",
    "label = image_classes[num]\n",
    "\n",
    "\n",
    "predict(img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For some fun \n",
    "# We can download new images from the web and test our model on them\n",
    "# I have used the bing_image_downloader library to download the images\n",
    "# You can install it using `pip install bing_image_downloader`\n",
    "\n",
    "import shutil\n",
    "def predict_web():\n",
    "    input_query = input()\n",
    "    from bing_image_downloader import downloader\n",
    "    pokemons = [names.lower() for names in pokemon_names]\n",
    "    if input_query.lower() in pokemons:\n",
    "        downloader.download(input_query,limit=3,output_dir='dataset',adult_filter_off=True,force_replace=False,verbose=False)\n",
    "        for image in os.listdir(f'dataset/{input_query}'):\n",
    "            try:\n",
    "                predict(f'dataset/{input_query}/'+image, class_to_int[input_query.title()])\n",
    "                return\n",
    "            except:\n",
    "                continue\n",
    "        print(\"Something went wrong, please try again\")\n",
    "    else:\n",
    "        print(f'Please enter a valid generation 1 pokemon name')\n",
    "    shutil.rmtree(f'dataset/{input_query}', ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try it out\n",
    "# Downloading may take some time (1-2 minutes)\n",
    "\n",
    "predict_web()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
